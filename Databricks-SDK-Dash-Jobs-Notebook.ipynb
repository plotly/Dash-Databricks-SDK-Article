{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc99cad2-39a2-4794-a2bf-ac7eff259bfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install prophet\n",
    "%pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7026f263-1557-4e6b-a1a3-9191aaf4812e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Here we create our Databricks notebooks inputs that Dash will utilize to fill in interactive options\n",
    "dbutils.widgets.text(\"us-state\", \"All States\", \"State Dropdown\")\n",
    "dbutils.widgets.text(\"forecast-forward-days\", \"180\", \"Forecast days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1667f77f-a551-474f-a861-a4caeba806e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Using Databricks' PySpark interface\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ProductForecasting\").getOrCreate()\n",
    "\n",
    "# Assuming the dataset is stored in a CSV format (adjust as needed)\n",
    "product_data = spark.read.csv(\"/databricks-datasets/retail-org/*\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d24585ec-bf5a-4187-9036-b9871f3b5228",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime, to_date\n",
    "\n",
    "# Grab relevant columns from the source data\n",
    "selected_data = product_data.select(\"customer_id\", \"state\", \"city\", \"valid_from\", \"units_purchased\", \"loyalty_segment\")\n",
    "\n",
    "# Convert the `valid_from` column from a UNIX timestamp to a date\n",
    "cleaned_data = selected_data.withColumn(\"purchase_date\", to_date(from_unixtime(\"valid_from\")))\n",
    "\n",
    "# Show the data with the new date column (COMMENTED OUT)\n",
    "# cleaned_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0906a2a-1370-478a-bbc2-5960749aa1b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_unixtime, to_date\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ProductForecasting\").getOrCreate()\n",
    "\n",
    "# Assuming the dataset is stored in a CSV format (adjust as needed)\n",
    "product_data = spark.read.csv(\"/databricks-datasets/retail-org/*\", header=True, inferSchema=True)\n",
    "\n",
    "selected_data = product_data.select(\"customer_id\", \"state\", \"city\", \"valid_from\", \"units_purchased\", \"loyalty_segment\")\n",
    "\n",
    "# Convert the `valid_from` column from a UNIX timestamp to a date\n",
    "cleaned_data = selected_data.withColumn(\"purchase_date\", to_date(from_unixtime(\"valid_from\")))\n",
    "cleaned_data = cleaned_data.filter(col(\"units_purchased\").rlike(\"^[0-9]+(\\.[0-9]+)?$\"))\n",
    "\n",
    "# Filter by state based on the widget value\n",
    "selected_state = dbutils.widgets.get(\"us-state\")\n",
    "if selected_state != \"All States\":\n",
    "    cleaned_data = cleaned_data.filter(col(\"state\") == selected_state)\n",
    "\n",
    "# COMMENTING OUT SHOW STATEMENT\n",
    "# cleaned_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8af43970-4e1e-4bd5-b3ba-d5fccc282475",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# Convert the Spark DataFrame to Pandas DataFrame\n",
    "pdf = cleaned_data.select(to_date('purchase_date').alias('ds'), 'units_purchased').toPandas()\n",
    "pdf['units_purchased'] = pdf['units_purchased'].astype(float)\n",
    "pdf.rename(columns={'units_purchased': 'y'}, inplace=True)\n",
    "\n",
    "# Prepare data for Prophet\n",
    "prophet_df = pdf.groupby('ds').sum().reset_index()\n",
    "\n",
    "# Initialize Prophet and fit the model\n",
    "model = Prophet(yearly_seasonality=True, daily_seasonality=True)\n",
    "model.fit(prophet_df)\n",
    "\n",
    "# Predict X days into the future\n",
    "num_days = int(dbutils.widgets.get(\"forecast-forward-days\"))  # Example: predict 30 days into the future; change this value as needed\n",
    "future = model.make_future_dataframe(periods=num_days)\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Plot the forecasts\n",
    "fig = plot_plotly(model, forecast)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    "    width=None,  # removing hardcoded width\n",
    "    height=None,  # removing hardcoded height\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    # White background\n",
    "    plot_bgcolor=\"#F9F7F4\",\n",
    "    paper_bgcolor=\"#F9F7F4\",\n",
    "    # Titles and fonts\n",
    "    title=\"Forecast Results\",\n",
    "    title_font=dict(size=24, family=\"Arial, sans-serif\", color=\"#1B3139\"),\n",
    "    # Axis labels\n",
    "    xaxis=dict(\n",
    "        title=\"Number of product units\",\n",
    "        titlefont=dict(size=18, color=\"#1B3139\"),\n",
    "        showgrid=True,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        gridwidth=0.5,\n",
    "        zerolinecolor=\"lightgrey\",\n",
    "        zerolinewidth=0.5,\n",
    "        tickfont=dict(size=14, color=\"#1B3139\"),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Order date\",\n",
    "        titlefont=dict(size=18, color=\"#1B3139\"),\n",
    "        showgrid=True,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        gridwidth=0.5,\n",
    "        zerolinecolor=\"lightgrey\",\n",
    "        zerolinewidth=0.5,\n",
    "        tickfont=dict(size=14, color=\"#1B3139\"),\n",
    "    ),\n",
    "    # Legend styling\n",
    "    legend=dict(font=dict(size=14, color=\"grey\")),\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20009568-068e-4860-81de-e01fad301dcb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import plotly.tools as tls\n",
    "import json\n",
    "import plotly.utils\n",
    "\n",
    "# Write the Plotly figure to JSON\n",
    "fig_json = json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "# Store the JSON in Databricks File Storage\n",
    "path_to_save = \"/tmp/forecast_plot.json\"\n",
    "dbutils.fs.put(path_to_save, fig_json, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dfaf4de-5061-4272-91ae-c71077844878",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 624314809918208,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks-SDK-Dash-Jobs-Notebook",
   "widgets": {
    "forecast-forward-days": {
     "currentValue": "180",
     "nuid": "250e8734-34d4-44e5-82ee-79ec8fc2a426",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "180",
      "label": "Forecast days",
      "name": "forecast-forward-days",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "state": {
     "currentValue": "CA",
     "nuid": "e6478a9d-f696-47ec-9fe8-872f99481bc4",
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "CA",
      "label": null,
      "name": "state",
      "options": {
       "widgetType": "dropdown",
       "choices": [
        "CA",
        "IL",
        "MI",
        "NY",
        "OR",
        "VA"
       ]
      }
     }
    },
    "table": {
     "currentValue": "",
     "nuid": "1f0feb77-30d0-4aa9-88b0-c430db8314e1",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "table",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "us-state": {
     "currentValue": "All States",
     "nuid": "25b289b1-d252-41e2-a357-10f3bc08b7ed",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "All States",
      "label": "State Dropdown",
      "name": "us-state",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
